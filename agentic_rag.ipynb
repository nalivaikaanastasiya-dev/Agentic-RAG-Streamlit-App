{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKS2ihB70Bf/9VdPJa/9TQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalivaikaanastasiya-dev/Agentic-RAG-Streamlit-App/blob/main/agentic_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# agentic_rag.ipynb\n",
        "\n",
        "# 1️⃣ Установка и импорт\n",
        "!pip install -q langchain langchain-groq tavily-python faiss-cpu python-dotenv\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import GroqEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import Groq\n",
        "\n",
        "# 2️⃣ Загрузка ключей из .env\n",
        "load_dotenv()\n",
        "\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")  # опционально\n",
        "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")  # опционально\n",
        "\n",
        "assert GROQ_API_KEY, \"GROQ_API_KEY не задан\"\n",
        "assert TAVILY_API_KEY, \"TAVILY_API_KEY не задан\"\n",
        "\n",
        "# 3️⃣ Инициализация LLM и эмбеддингов\n",
        "llm = Groq(model=\"gpt-3.5\", api_key=GROQ_API_KEY)\n",
        "\n",
        "embeddings = GroqEmbeddings(api_key=GROQ_API_KEY)\n",
        "\n",
        "# 4️⃣ Загружаем/создаём KB\n",
        "# Пример: список документов\n",
        "kb_docs = [\n",
        "    {\"text\": \"Agentic AI systems follow the loop: interpret goal, plan, act, reflect, answer.\", \"source\": \"kb:agentic\"},\n",
        "    {\"text\": \"Tools should be used only when necessary.\", \"source\": \"kb:tools\"},\n",
        "    {\"text\": \"Always cite sources like KB or web pages.\", \"source\": \"kb:citation\"}\n",
        "]\n",
        "\n",
        "# Создание векторного индекса\n",
        "texts = [d[\"text\"] for d in kb_docs]\n",
        "vectorstore = FAISS.from_texts(texts, embeddings)\n",
        "\n",
        "# 5️⃣ Создание RetrievalQA chain\n",
        "prompt_template = \"\"\"\n",
        "Answer the user question based on the retrieved documents.\n",
        "Cite sources inline using [source] notation.\n",
        "Keep answer concise (2–4 sentences).\n",
        "\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=[\"question\"])\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# 6️⃣ Функция для Streamlit\n",
        "def answer_question(query: str):\n",
        "    \"\"\"\n",
        "    Возвращает ответ агента на запрос query.\n",
        "    Результат содержит текст и источники.\n",
        "    \"\"\"\n",
        "    res = qa_chain(query)\n",
        "    answer_text = res['result']\n",
        "    sources = [doc.metadata.get('source', f\"doc{i}\") for i, doc in enumerate(res['source_documents'])]\n",
        "\n",
        "    # Форматирование\n",
        "    answer_with_sources = answer_text + \"\\n\\nSources:\\n\" + \"\\n\".join(f\"[{i+1}] {s}\" for i, s in enumerate(sources))\n",
        "    return answer_with_sources\n",
        "\n",
        "# 7️⃣ Тест\n",
        "questions = [\n",
        "    \"What is an agentic AI loop?\",\n",
        "    \"When should an agent use tools?\",\n",
        "    \"How should sources be cited?\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(\"Q:\", q)\n",
        "    print(answer_question(q))\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "id": "DwHG5OYLhAGo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}